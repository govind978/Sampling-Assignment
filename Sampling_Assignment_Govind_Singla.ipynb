{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4fc4e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11269709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14f07b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns = {'Time', 'Class'}, axis = 1), df['Class'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f9005f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    534\n",
       "1      6\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "32fe0c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    229\n",
       "1      3\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f1c3d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "035dcab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "model = LogisticRegression()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc5a5ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a0be45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec82198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4d4a4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08feb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c9a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a39fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "model = LogisticRegression()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7456b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "54704688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "465d04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cddc3311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b87d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13219c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "70e60b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "model = LogisticRegression()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "536cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7cd8ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "08aab6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "53951ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68946447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d54c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a0b7b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import ADASYN\n",
    "model = LogisticRegression()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eed25f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "212237b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f87709a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1bfb78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbdd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc0c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bce34b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.combine import SMOTETomek\n",
    "model = LogisticRegression()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "81e48353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e0f36312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b990ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "27f434bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627bfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b33ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "62bf89aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "model = LogisticRegression()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c5911663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "062abd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "939cd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0342a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dc5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdba21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3dec455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3cc80e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "115d7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f8ff7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9da0a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ef69990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f290f838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sample Technique</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampling</td>\n",
       "      <td>0.935345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K Nearest Neighbour</td>\n",
       "      <td>Random Over Sampling</td>\n",
       "      <td>0.943966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Over Sampling</td>\n",
       "      <td>0.676724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>Random Over Sampling</td>\n",
       "      <td>0.961207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Random Over Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampling</td>\n",
       "      <td>0.767241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K Nearest Neighbour</td>\n",
       "      <td>Random Under Sampling</td>\n",
       "      <td>0.676724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampling</td>\n",
       "      <td>0.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>Random Under Sampling</td>\n",
       "      <td>0.767241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Random Under Sampling</td>\n",
       "      <td>0.392241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.935345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K Nearest Neighbour</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.918103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.672414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.961207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.926724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>K Nearest Neighbour</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.918103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVC</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.672414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.961207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Tomek Links</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>K Nearest Neighbour</td>\n",
       "      <td>Tomek Links</td>\n",
       "      <td>0.918103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC</td>\n",
       "      <td>Tomek Links</td>\n",
       "      <td>0.672414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>Tomek Links</td>\n",
       "      <td>0.961207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Tomek Links</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Stratified Sampling</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>K Nearest Neighbour</td>\n",
       "      <td>Stratified Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVC</td>\n",
       "      <td>Stratified Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>Stratified Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Stratified Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Systematic Sampling</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>K Nearest Neighbour</td>\n",
       "      <td>Systematic Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVC</td>\n",
       "      <td>Systematic Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>Systematic Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Systematic Sampling</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model       Sample Technique  Accuracy\n",
       "0        Logistic Regression   Random Over Sampling  0.935345\n",
       "1        K Nearest Neighbour   Random Over Sampling  0.943966\n",
       "2                        SVC   Random Over Sampling  0.676724\n",
       "3             XGB Classifier   Random Over Sampling  0.961207\n",
       "4   Random Forest Classifier   Random Over Sampling  0.987069\n",
       "5        Logistic Regression  Random Under Sampling  0.767241\n",
       "6        K Nearest Neighbour  Random Under Sampling  0.676724\n",
       "7                        SVC  Random Under Sampling  0.534483\n",
       "8             XGB Classifier  Random Under Sampling  0.767241\n",
       "9   Random Forest Classifier  Random Under Sampling  0.392241\n",
       "10       Logistic Regression                  SMOTE  0.935345\n",
       "11       K Nearest Neighbour                  SMOTE  0.918103\n",
       "12                       SVC                  SMOTE  0.672414\n",
       "13            XGB Classifier                  SMOTE  0.961207\n",
       "14  Random Forest Classifier                  SMOTE  0.987069\n",
       "15       Logistic Regression                 ADASYN  0.926724\n",
       "16       K Nearest Neighbour                 ADASYN  0.918103\n",
       "17                       SVC                 ADASYN  0.672414\n",
       "18            XGB Classifier                 ADASYN  0.961207\n",
       "19  Random Forest Classifier                 ADASYN  0.987069\n",
       "20       Logistic Regression            Tomek Links  0.931034\n",
       "21       K Nearest Neighbour            Tomek Links  0.918103\n",
       "22                       SVC            Tomek Links  0.672414\n",
       "23            XGB Classifier            Tomek Links  0.961207\n",
       "24  Random Forest Classifier            Tomek Links  0.987069\n",
       "25       Logistic Regression    Stratified Sampling  0.982759\n",
       "26       K Nearest Neighbour    Stratified Sampling  0.987069\n",
       "27                       SVC    Stratified Sampling  0.987069\n",
       "28            XGB Classifier    Stratified Sampling  0.987069\n",
       "29  Random Forest Classifier    Stratified Sampling  0.987069\n",
       "30       Logistic Regression    Systematic Sampling  0.982759\n",
       "31       K Nearest Neighbour    Systematic Sampling  0.987069\n",
       "32                       SVC    Systematic Sampling  0.987069\n",
       "33            XGB Classifier    Systematic Sampling  0.987069\n",
       "34  Random Forest Classifier    Systematic Sampling  0.987069"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "edb3b4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape the DataFrame to have models as rows and samplers as columns\n",
    "table = pd.pivot_table(results_df, values='Accuracy', index=['Model'], columns=['Sample Technique'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2a0d01be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sample Technique</th>\n",
       "      <th>ADASYN</th>\n",
       "      <th>Random Over Sampling</th>\n",
       "      <th>Random Under Sampling</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>Stratified Sampling</th>\n",
       "      <th>Systematic Sampling</th>\n",
       "      <th>Tomek Links</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbour</th>\n",
       "      <td>0.918103</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.918103</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.918103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.926724</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>0.935345</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.392241</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.672414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Classifier</th>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.961207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sample Technique            ADASYN  Random Over Sampling  \\\n",
       "Model                                                      \n",
       "K Nearest Neighbour       0.918103              0.943966   \n",
       "Logistic Regression       0.926724              0.935345   \n",
       "Random Forest Classifier  0.987069              0.987069   \n",
       "SVC                       0.672414              0.676724   \n",
       "XGB Classifier            0.961207              0.961207   \n",
       "\n",
       "Sample Technique          Random Under Sampling     SMOTE  \\\n",
       "Model                                                       \n",
       "K Nearest Neighbour                    0.676724  0.918103   \n",
       "Logistic Regression                    0.767241  0.935345   \n",
       "Random Forest Classifier               0.392241  0.987069   \n",
       "SVC                                    0.534483  0.672414   \n",
       "XGB Classifier                         0.767241  0.961207   \n",
       "\n",
       "Sample Technique          Stratified Sampling  Systematic Sampling  \\\n",
       "Model                                                                \n",
       "K Nearest Neighbour                  0.987069             0.987069   \n",
       "Logistic Regression                  0.982759             0.982759   \n",
       "Random Forest Classifier             0.987069             0.987069   \n",
       "SVC                                  0.987069             0.987069   \n",
       "XGB Classifier                       0.987069             0.987069   \n",
       "\n",
       "Sample Technique          Tomek Links  \n",
       "Model                                  \n",
       "K Nearest Neighbour          0.918103  \n",
       "Logistic Regression          0.931034  \n",
       "Random Forest Classifier     0.987069  \n",
       "SVC                          0.672414  \n",
       "XGB Classifier               0.961207  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f515b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we can see highest accuracy is given with Stratified Sampling & systematic sampling using Random Forest MOdel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
