{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc4e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11269709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f07b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = {'Time', 'Class'}, axis = 1), df['Class'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c3d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035dcab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "model = LogisticRegression()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc5a5ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0be45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec82198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d4a4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = RandomOverSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Random Over Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08feb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c9a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a39fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "model = LogisticRegression()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7456b8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54704688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "465d04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cddc3311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = RandomUnderSampler()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Random Under Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b87d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13219c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70e60b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "model = LogisticRegression()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "536cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cd8ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08aab6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53951ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = SMOTE()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'SMOTE', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68946447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d54c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0b7b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import ADASYN\n",
    "model = LogisticRegression()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eed25f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "212237b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f87709a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bfb78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = ADASYN()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'ADASYN', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbdd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc0c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bce34b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.combine import SMOTETomek\n",
    "model = LogisticRegression()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81e48353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0f36312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b990ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27f434bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = SMOTETomek()\n",
    "x_resampled, y_resampled = sample.fit_resample(X_train, y_train)\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Tomek Links', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627bfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b33ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62bf89aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "model = LogisticRegression()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5911663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "062abd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "939cd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0342a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "sample = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, val_idx in sample.split(X_train, y_train):\n",
    "    x_resampled, y_resampled = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Stratified Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dc5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdba21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3dec455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Logistic Regression', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cc80e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'K Nearest Neighbour', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "115d7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'SVC', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8ff7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'XGB Classifier', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9da0a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "step = 2\n",
    "indices = list(range(0, len(X_train), step))\n",
    "x_resampled, y_resampled = X_train.iloc[indices], y_train.iloc[indices]\n",
    "model.fit(x_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "results.append({'Model': 'Random Forest Classifier', 'Sample Technique': 'Systematic Sampling', 'Accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edb3b4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "display = pd.pivot_table(results_df, values='Accuracy', index=['Model'], columns=['Sample Technique'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a0d01be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sample Technique</th>\n",
       "      <th>ADASYN</th>\n",
       "      <th>Random Over Sampling</th>\n",
       "      <th>Random Under Sampling</th>\n",
       "      <th>SMOTE</th>\n",
       "      <th>Stratified Sampling</th>\n",
       "      <th>Systematic Sampling</th>\n",
       "      <th>Tomek Links</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbour</th>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.943966</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.918103</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.918103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.926724</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.926724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.762931</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.668103</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.672414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Classifier</th>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.564655</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.987069</td>\n",
       "      <td>0.961207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sample Technique            ADASYN  Random Over Sampling  \\\n",
       "Model                                                      \n",
       "K Nearest Neighbour       0.922414              0.943966   \n",
       "Logistic Regression       0.926724              0.939655   \n",
       "Random Forest Classifier  0.987069              0.987069   \n",
       "SVC                       0.672414              0.672414   \n",
       "XGB Classifier            0.961207              0.961207   \n",
       "\n",
       "Sample Technique          Random Under Sampling     SMOTE  \\\n",
       "Model                                                       \n",
       "K Nearest Neighbour                    0.267241  0.918103   \n",
       "Logistic Regression                    0.780172  0.931034   \n",
       "Random Forest Classifier               0.762931  0.987069   \n",
       "SVC                                    0.668103  0.672414   \n",
       "XGB Classifier                         0.564655  0.961207   \n",
       "\n",
       "Sample Technique          Stratified Sampling  Systematic Sampling  \\\n",
       "Model                                                                \n",
       "K Nearest Neighbour                  0.987069             0.987069   \n",
       "Logistic Regression                  0.982759             0.982759   \n",
       "Random Forest Classifier             0.987069             0.987069   \n",
       "SVC                                  0.987069             0.987069   \n",
       "XGB Classifier                       0.987069             0.987069   \n",
       "\n",
       "Sample Technique          Tomek Links  \n",
       "Model                                  \n",
       "K Nearest Neighbour          0.918103  \n",
       "Logistic Regression          0.926724  \n",
       "Random Forest Classifier     0.987069  \n",
       "SVC                          0.672414  \n",
       "XGB Classifier               0.961207  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f515b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we can see highest accuracy is given with Stratified Sampling & systematic sampling using Random Forest MOdel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
